{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c215aeb5dc381afb5f8a553c401346b",
     "grade": false,
     "grade_id": "cell-ce50a5b24a1e2adf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# SLAM Unit B - Part 2\n",
    "## *Featureless* localization\n",
    "As we have seen in Part 1, sometimes there are just not enough landmarks in our field of view. Since our approach needs at least two matching landmarks, we will often loose the ability to correct the position. During such phases, our estimate of the pose will diverge from the true pose, eventually leading to a situation where we are unable to recover.\n",
    "\n",
    "However, although only a small percentage of the laser scanner measurements hit a landmark, almost all of the remaining measurements are valid as well. They measure the environment, in our case, the boundaries of the arena. Since the environment is static, we may use it for localization as well. This is what we explore in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"560\"\n",
       "            height=\"315\"\n",
       "            src=\"//av.tib.eu/player/48986\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2104357fdc0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YouTube = True  # Uncomment this line to get YouTube videos instead of TIB AV.\n",
    "# If you don't see a video below, run this cell.\n",
    "from IPython.display import IFrame\n",
    "IFrame(\"https://www.youtube.com/embed/kTg7mGL48Jw\" if \"YouTube\" in globals() else \"//av.tib.eu/player/48986\",\n",
    "       width=560, height=315)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "240b5513b7a49d510ffbe76a82023f59",
     "grade": false,
     "grade_id": "cell-b3a046af49ff3d4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Finding correspondences\n",
    "### Programming assignment: for each point which is close enough to a wall, set up a correspondence (10 Points).\n",
    "Here are some hints:\n",
    "- Although this is the case in our arena, do not assume in your code that the left boundary is at $x=0$ (and the lower boundary is at $y=0$).\n",
    "- As mentioned in the video, if a point is close to two boundaries (e.g. a point in the lower left corner fits `arena_left` *and* `arena_bottom`), pick one of them, in the order in which they appear in the parameter list: `arena_left`, `arena_right`, `arena_bottom`, `arena_top`. For example, if the point fits `arena_left` *and* `arena_bottom`, set up only one correspondence, namely to the projected point on `arena_left`).\n",
    "- Also keep in mind that points completely outside the arena should not be assigned. For example, even if $x$ fulfills `arena_left`$-\\varepsilon < x <$ `arena_left` $+\\varepsilon$, there should be no corresponcence if $y$ is outside, i.e., $y\\leq$ `arena_bottom` or $y\\geq$ `arena_top`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fda4bdf119b441827ce4098d159e4da",
     "grade": false,
     "grade_id": "cell-160f35e4d80590d4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Given a set of points, checks for every point p if it is closer than\n",
    "# eps to the left, right, bottom or top wall of the arena. If so,\n",
    "# adds the point to left_list, and the closest point on the wall to\n",
    "# right_list.\n",
    "def get_corresponding_points_on_wall(points,\n",
    "                                     arena_left = 0.0, arena_right = 2000.0,\n",
    "                                     arena_bottom = 0.0, arena_top = 2000.0,\n",
    "                                     eps = 150.0):\n",
    "    # YOUR CODE HERE\n",
    "    left_list=[]\n",
    "    right_list=[]\n",
    "\n",
    "    for p in points:\n",
    "        x,y=p[0],p[1]\n",
    "        if abs(x-arena_left)<eps and (y-arena_bottom>-eps and y-arena_top<eps):\n",
    "            left_list.append(p)\n",
    "            right_list.append((arena_left,y))\n",
    "        elif abs(x-arena_right)<eps and (y-arena_bottom>-eps and y-arena_top<eps):\n",
    "            left_list.append(p)\n",
    "            right_list.append((arena_right,y))\n",
    "                            \n",
    "        elif abs(y-arena_bottom)<eps and (x-arena_left>-eps and x-arena_right<eps):\n",
    "            left_list.append(p)\n",
    "            right_list.append((x,arena_bottom))\n",
    "        elif abs(y-arena_top)<eps and (x-arena_left>-eps and x-arena_right<eps):\n",
    "            left_list.append(p)\n",
    "            right_list.append((x,arena_top))\n",
    "\n",
    "    #raise NotImplementedError()\n",
    "    return left_list, right_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "834c98dc3ae8e0c80605069f08f6d1c2",
     "grade": false,
     "grade_id": "cell-0c7dae1aea7defe5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Let's test this.\n",
    "(Let me assure you that this test is actually much longer than the code you are supposed to implement above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2a2423df8cb2b63b45b75b4468d502f",
     "grade": true,
     "grade_id": "cell-cbf5b205f8bd1bd6",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from random import random, randint\n",
    "def public_test(the_get_corresponding_points_on_wall):\n",
    "    # Define all the points in a grid around 0 with borders at +/-1, eps=0.5.\n",
    "    # Then, according to the precedence rules (left, right, bottom, top) given\n",
    "    # in the video, the assignment should be:\n",
    "    #  00000\n",
    "    #  0ltr0\n",
    "    #  0l0r0\n",
    "    #  0lbr0\n",
    "    #  00000\n",
    "    # where 0,l,r,b,t corresponds to outside, left, right, bottom, top.\n",
    "    num_points = 40\n",
    "\n",
    "    # Make two experiments, one \"plain\" and one with introduced scale and shift.\n",
    "    for s, tx, ty in [(1,0,0), (random()+0.5, random()*10-5, random()*10-5)]:\n",
    "        # Define the points in the range -2.5...2.5 randomly, but avoid\n",
    "        # \"0.5 areas\" to guard against rounding errors.\n",
    "        points = [(random()*0.99-0.5+randint(-2,2),\n",
    "                   random()*0.99-0.5+randint(-2,2)) for i in range(num_points)]\n",
    "        cell_indices = [(round(x), round(y)) for (x,y) in points]\n",
    "        # Left list contains all points which are not outside (in the 0 areas).\n",
    "        left = [ p for (p, ci) in zip(points, cell_indices)\\\n",
    "                 if ci!=(0,0) and max(abs(ci[0]),abs(ci[1])) <= 1]\n",
    "        # Right list is more elaborate.\n",
    "        right = []\n",
    "        for (p, ci) in zip(points, cell_indices):\n",
    "            if max(abs(ci[0]),abs(ci[1])) > 1: continue\n",
    "            if   ci[0] == -1: right.append((  -1, p[1]))  # left\n",
    "            elif ci[0] ==  1: right.append((   1, p[1]))  # right\n",
    "            elif ci[1] == -1: right.append((p[0],   -1))  # bottom\n",
    "            elif ci[1] ==  1: right.append((p[0],    1))  # top\n",
    "        # Now introduce scale and shift.\n",
    "        points = [(p[0]*s+tx, p[1]*s+ty) for p in points]\n",
    "        left   = [(p[0]*s+tx, p[1]*s+ty) for p in left]\n",
    "        right  = [(p[0]*s+tx, p[1]*s+ty) for p in right]\n",
    "        \n",
    "        # Now call user function.\n",
    "        l, r = the_get_corresponding_points_on_wall(points[:],\n",
    "            -s+tx, s+tx, -s+ty, s+ty, 0.5*s)\n",
    "        # First guard against different list lengths.\n",
    "        if len(l) != len(r):\n",
    "            print(\"The returned left and right lists have different length.\")\n",
    "            return False\n",
    "\n",
    "        # Check if the lists coincide. Sort them to guard against different orders.\n",
    "        leftright = sorted(zip(left,right))\n",
    "        lr = sorted(zip(l,r))\n",
    "        if lr != leftright:\n",
    "            print(\"For pointlist:\")\n",
    "            print(\"\".join(\"(% .4f,% .4f)\\n\" % p for p in points))\n",
    "            print(\"Expected left -> right assignment:\")\n",
    "            print(\"\".join(\"(% .4f,% .4f)->(% .4f,% .4f)\\n\" %\\\n",
    "                          (p[0],p[1],q[0],q[1]) for p, q in leftright))\n",
    "            print(\"Returned left -> right assignment:\")\n",
    "            print(\"\".join(\"(% .4f,% .4f)->(% .4f,% .4f)\\n\" %\\\n",
    "                          (p[0],p[1],q[0],q[1]) for p, q in lr))\n",
    "            # Mention if results have different length.\n",
    "            if len(lr) != len(leftright):\n",
    "                print(\"Expected and returned lists differ in length.\\n\")\n",
    "            # In addition, make a list of different entries.\n",
    "            print(\"Entries which are different, expected vs. returned:\")\n",
    "            print(\"\".join(\n",
    "                \"(% .4f,% .4f)->(% .4f,% .4f) vs. \"\\\n",
    "                \"(% .4f,% .4f)->(% .4f,% .4f)\\n\" %\\\n",
    "                (pp[0][0], pp[0][1], pp[1][0], pp[1][1],\n",
    "                 qq[0][0], qq[0][1], qq[1][0], qq[1][1]) \\\n",
    "                for pp, qq in zip(leftright, lr) if pp != qq))\n",
    "            return False\n",
    "    return True\n",
    "assert(public_test(get_corresponding_points_on_wall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "777a2e6d94b3df13fba950a40f5572c5",
     "grade": false,
     "grade_id": "cell-1113fd2729cc6292",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that it is tested, execute it to produce `find_wall_pairs.txt` which we will then inspect right after this, using the logfile viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample the scan. For each point, find a closest point on the\n",
    "# wall of the arena.\n",
    "# 05_a_find_wall_pairs\n",
    "from lego_robot import *\n",
    "from slam_b_library import filter_step, compute_cartesian_coordinates,\\\n",
    "    write_cylinders\n",
    "\n",
    "# Takes one scan and subsamples the measurements, so that every sampling'th\n",
    "# point is taken. Returns a list of (x, y) points in the scanner's\n",
    "# coordinate system.\n",
    "def get_subsampled_points(scan, sampling = 10):\n",
    "    # Subsample from scan\n",
    "    index_range_tuples = []\n",
    "    for i in range(0, len(scan), sampling):\n",
    "        index_range_tuples.append( (i, scan[i]) )\n",
    "    return compute_cartesian_coordinates(index_range_tuples, 0.0)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # The constants we used for the filter_step.\n",
    "    scanner_displacement = 30.0\n",
    "    ticks_to_mm = 0.349\n",
    "    robot_width = 150.0\n",
    "\n",
    "    # The start pose we obtained miraculously.\n",
    "    pose = (1850.0, 1897.0, 3.717551306747922)\n",
    "\n",
    "    # Read the logfile which contains all scans.\n",
    "    logfile = LegoLogfile()\n",
    "    logfile.read(\"robot4_motors.txt\")\n",
    "    logfile.read(\"robot4_scan.txt\")\n",
    "\n",
    "    # Iterate over all positions.\n",
    "    out_file = open(\"find_wall_pairs.txt\", \"w\")\n",
    "    for i in range(len(logfile.scan_data)):\n",
    "        # Compute the new pose.\n",
    "        pose = filter_step(pose, logfile.motor_ticks[i],\n",
    "                           ticks_to_mm, robot_width,\n",
    "                           scanner_displacement)\n",
    "\n",
    "        # Subsample points.\n",
    "        subsampled_points = get_subsampled_points(logfile.scan_data[i])\n",
    "        world_points = [LegoLogfile.scanner_to_world(pose, c)\n",
    "                        for c in subsampled_points]\n",
    "\n",
    "        # Get corresponding points on wall.\n",
    "        left, right = get_corresponding_points_on_wall(world_points)\n",
    "\n",
    "        # Write to file.\n",
    "        # The pose.\n",
    "        print(\"F %f %f %f\" % pose, file=out_file)\n",
    "        # Write the scanner points and corresponding points.\n",
    "        write_cylinders(out_file, \"W C\", left + right)\n",
    "\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638c3195145e448cacb62a5a4f760baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Output(layout=Layout(width='600px')), Output(layout=Layout(width='600px')))), Ou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipy_logfile_viewer as lfv\n",
    "v = lfv.IPYLogfileViewer(files=[\"find_wall_pairs.txt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9ebaf0bf46af30c0c38eaa703f0b5af",
     "grade": false,
     "grade_id": "cell-d0e6cce7dc4104e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Correcting the trajectory using *ICP*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49f750b8b2800c32f6c1330049b43183",
     "grade": false,
     "grade_id": "cell-fb2f94acb216410e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"560\"\n",
       "            height=\"315\"\n",
       "            src=\"//av.tib.eu/player/48987\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2107e5f1880>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you don't see a video below, run this cell.\n",
    "from IPython.display import IFrame\n",
    "IFrame(\"https://www.youtube.com/embed/rM-CajaLZi4\" if \"YouTube\" in globals() else \"//av.tib.eu/player/48987\",\n",
    "       width=560, height=315)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a60367d098bc410b906aafcd3267701",
     "grade": false,
     "grade_id": "cell-7b53b22ae9e00053",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Use the assigned point pairs to estimate a transformation and apply it to the pose.\n",
    "This is no programming assignment, since there is nothing to do $-$ all required functions are available already.\n",
    "\n",
    "Since you are working with notebooks right now, the `import` trick discussed in the video is not very handy. However, we still need some functions which you have programmed in *Part 1*. The easiest way to proceed is that you copy & paste the functions `estimate_transform` and `correct_pose`, which were assignments in the *Part 1* notebook, to the cell below, at the indicated locations.\n",
    "\n",
    "Then, run the following two cells to reproduce the result shown in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "99c24144e9b39e559b0dea823901eb65",
     "grade": false,
     "grade_id": "cell-f275c077cb98c8a7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Pasted from Part 1 notebook.\n",
    "import numpy as np\n",
    "import math\n",
    "def compute_center(point_list):\n",
    "    # Safeguard against empty list.\n",
    "    if not point_list:\n",
    "        return (0.0, 0.0)\n",
    "    # If not empty, sum up and divide.\n",
    "    sx = sum([p[0] for p in point_list])\n",
    "    sy = sum([p[1] for p in point_list])\n",
    "    return (float(sx) / len(point_list), float(sy) / len(point_list))\n",
    "\n",
    "# Pasted from the Part 1 notebook.\n",
    "def apply_transform(trafo, p):\n",
    "    la, c, s, tx, ty = trafo\n",
    "    lac = la * c\n",
    "    las = la * s\n",
    "    x = lac * p[0] - las * p[1] + tx\n",
    "    y = las * p[0] + lac * p[1] + ty\n",
    "    return (x, y)\n",
    "\n",
    "# Since the estimate_transform is in the Part 1 notebook, you will have\n",
    "# to paste your solution here.\n",
    "def estimate_transform(left_list, right_list, fix_scale = False):\n",
    "    # Compute left and right center.\n",
    "    lc = compute_center(left_list)\n",
    "    rc = compute_center(right_list)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    l_p=[]\n",
    "    r_p=[]\n",
    "    for i in range (len(left_list)):\n",
    "\n",
    "        # l_p.append(np.diff([left_list[i],lc]))\n",
    "        # r_p.append(np.diff([right_list[i],rc])) np.diff rechnet nur die absolute Differenz, stattdessen\n",
    "        # sollte die Substraktion eingeführt werden\n",
    "        l_p = [tuple(np.subtract(l,lc)) for l in left_list]\n",
    "        r_p = [tuple(np.subtract(r,rc)) for r in right_list]\n",
    "\n",
    "    cs, ss, rr, ll=0.0,0.0,0.0,0.0\n",
    "    for i in range (len(left_list)):\n",
    "\n",
    "        cs+=l_p[i][0]*r_p[i][0]+r_p[i][1]*l_p[i][1]\n",
    "        ss+=-r_p[i][0]*l_p[i][1]+r_p[i][1]*l_p[i][0]\n",
    "        rr+=r_p[i][0]**2+r_p[i][1]**2\n",
    "        ll+=l_p[i][0]**2+l_p[i][1]**2\n",
    "\n",
    "    if fix_scale:\n",
    "        la = 1.0\n",
    "    else:\n",
    "        la = sqrt(rr/ll)\n",
    "    if cs==0 and ss==0:\n",
    "        return None\n",
    "    else:    \n",
    "\n",
    "    # if cs==0 or ss==0:\n",
    "    #     return None\n",
    "    # else:    \n",
    "        c=cs/math.sqrt(cs**2+ss**2)\n",
    "        s=ss/math.sqrt(cs**2+ss**2)\n",
    "\n",
    "    tx=rc[0]-la*(c*lc[0]-s*lc[1])\n",
    "    ty=rc[1]-la*(s*lc[0]+c*lc[1])\n",
    "    #raise NotImplementedError()\n",
    "    return la, c, s, tx, ty\n",
    "\n",
    "# Also, you will have to paste your solution for correct_pose\n",
    "# from Part 1 to here.\n",
    "def correct_pose(pose, trafo):\n",
    "    # YOUR CODE HERE\n",
    "    la, c, s, tx, ty =trafo\n",
    "    x, y ,t=pose\n",
    "    #raise NotImplementedError()\n",
    "    [x,y]=apply_transform(trafo, (x,y))\n",
    "    t=t+atan2(s,c)\n",
    "    #raise NotImplementedError()\n",
    "    return (x, y, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample the scan. For each point, find a closest point on the\n",
    "# wall of the arena.\n",
    "# From those point pairs, estimate a transform and apply this to the pose.\n",
    "# 05_b_estimate_wall_transform\n",
    "from math import sqrt, atan2\n",
    "from lego_robot import *\n",
    "from slam_b_library import filter_step, write_cylinders\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # The constants we used for the filter_step.\n",
    "    scanner_displacement = 30.0\n",
    "    ticks_to_mm = 0.349\n",
    "    robot_width = 150.0\n",
    "\n",
    "    # The start pose we obtained miraculously.\n",
    "    pose = (1850.0, 1897.0, 3.717551306747922)\n",
    "\n",
    "    # Read the logfile which contains all scans.\n",
    "    logfile = LegoLogfile()\n",
    "    logfile.read(\"robot4_motors.txt\")\n",
    "    logfile.read(\"robot4_scan.txt\")\n",
    "\n",
    "    # Iterate over all positions.\n",
    "    out_file = open(\"estimate_wall_transform.txt\", \"w\")\n",
    "    for i in range(len(logfile.scan_data)):\n",
    "        # Compute the new pose.\n",
    "        pose = filter_step(pose, logfile.motor_ticks[i],\n",
    "                           ticks_to_mm, robot_width,\n",
    "                           scanner_displacement)\n",
    "\n",
    "        # Subsample points.\n",
    "        subsampled_points = get_subsampled_points(logfile.scan_data[i])\n",
    "        world_points = [LegoLogfile.scanner_to_world(pose, c)\n",
    "                        for c in subsampled_points]\n",
    "\n",
    "        # Get the transformation\n",
    "        left, right = get_corresponding_points_on_wall(world_points)\n",
    "        trafo = estimate_transform(left, right, fix_scale = True)        \n",
    "\n",
    "        # Correct the initial position using trafo. Also transform points.\n",
    "        if trafo:\n",
    "            pose = correct_pose(pose, trafo)\n",
    "            world_points = [apply_transform(trafo, p) for p in world_points]\n",
    "        else:\n",
    "            world_points = []\n",
    "\n",
    "        # Write to file.\n",
    "        # The pose.\n",
    "        print(\"F %f %f %f\" % pose, file=out_file)\n",
    "        # Write the scanner points and corresponding points.\n",
    "        write_cylinders(out_file, \"W C\", world_points)\n",
    "\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46b75023439f5eabf4d65864f832198e",
     "grade": false,
     "grade_id": "cell-7954cf085d226767",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Look at the result!\n",
    "This reproduces the result of the first part of the video.\n",
    "\n",
    "The good thing is that we obtain a corrected trajectory with a shape that looks globally correct. We never get lost!\n",
    "\n",
    "On the down side, it is not as smooth as we might have expected. When you go through the trajectory step by step, you will see that there are often situations where the wall points are turned with respect to the actual walls. As explained in the video, this is the case since the point correspondences we compute are actually wrong. Below, we will try to fix this using the *ICP* algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"289.7pt\" version=\"1.1\" viewBox=\"0 0 289.7 289.7\" width=\"289.7pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2022-03-19T22:52:25.973901</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 289.7 \r\nL 289.7 289.7 \r\nL 289.7 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 10.7 279 \r\nL 282.5 279 \r\nL 282.5 7.2 \r\nL 10.7 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\"/>\r\n   <g id=\"matplotlib.axis_2\"/>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 10.7 279 \r\nL 10.7 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 282.5 279 \r\nL 282.5 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 10.7 279 \r\nL 282.5 279 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 10.7 7.2 \r\nL 282.5 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"line2d_1\">\r\n    <path clip-path=\"url(#pe8f54f9cf8)\" d=\"M 24.29 211.05 \r\nL 146.6 211.05 \r\nL 146.6 88.74 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\r\n   </g>\r\n   <g id=\"text_1\">\r\n    <!-- x -->\r\n    <g transform=\"translate(152.7155 88.74)scale(0.1 -0.1)\">\r\n     <defs>\r\n      <path d=\"M 54.890625 54.6875 \r\nL 35.109375 28.078125 \r\nL 55.90625 0 \r\nL 45.3125 0 \r\nL 29.390625 21.484375 \r\nL 13.484375 0 \r\nL 2.875 0 \r\nL 24.125 28.609375 \r\nL 4.6875 54.6875 \r\nL 15.28125 54.6875 \r\nL 29.78125 35.203125 \r\nL 44.28125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-120\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-120\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"text_2\">\r\n    <!-- y -->\r\n    <g transform=\"translate(24.29 204.9345)scale(0.1 -0.1)\">\r\n     <defs>\r\n      <path d=\"M 32.171875 -5.078125 \r\nQ 28.375 -14.84375 24.75 -17.8125 \r\nQ 21.140625 -20.796875 15.09375 -20.796875 \r\nL 7.90625 -20.796875 \r\nL 7.90625 -13.28125 \r\nL 13.1875 -13.28125 \r\nQ 16.890625 -13.28125 18.9375 -11.515625 \r\nQ 21 -9.765625 23.484375 -3.21875 \r\nL 25.09375 0.875 \r\nL 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 11.921875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-121\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-121\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_7\">\r\n    <path clip-path=\"url(#pe8f54f9cf8)\" d=\"M 146.6 214.626316 \r\nC 147.54845 214.626316 148.458182 214.249493 149.128837 213.578837 \r\nC 149.799493 212.908182 150.176316 211.99845 150.176316 211.05 \r\nC 150.176316 210.10155 149.799493 209.191818 149.128837 208.521163 \r\nC 148.458182 207.850507 147.54845 207.473684 146.6 207.473684 \r\nC 145.65155 207.473684 144.741818 207.850507 144.071163 208.521163 \r\nC 143.400507 209.191818 143.023684 210.10155 143.023684 211.05 \r\nC 143.023684 211.99845 143.400507 212.908182 144.071163 213.578837 \r\nC 144.741818 214.249493 145.65155 214.626316 146.6 214.626316 \r\nz\r\n\" style=\"fill:#808080;stroke:#808080;stroke-linejoin:miter;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pe8f54f9cf8\">\r\n   <rect height=\"271.8\" width=\"271.8\" x=\"10.7\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipy_logfile_viewer as lfv\n",
    "v = lfv.IPYLogfileViewer(files=[\"estimate_wall_transform.txt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a83b4a1394921f1d92c586842c0f384",
     "grade": false,
     "grade_id": "cell-ac6addd559afa615",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Improving the result using *ICP*: programming assignment (15 Points).\n",
    "*ICP* stands for *iterative closest point* and this just means that we will iterate the steps of *correspondence finding* and *transformation estimation* for a few times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7af0d8b65b83050dc9aff17afa0aaf22",
     "grade": false,
     "grade_id": "cell-b767b7fb393e845b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# ICP: Iterate the steps of transforming the points, selecting point pairs, and\n",
    "# estimating the transform. Returns the final transformation.\n",
    "def get_icp_transform(world_points, iterations):\n",
    "    \n",
    "    # Iterate assignment and estimation of trafo a few times.\n",
    "    \n",
    "    # You may use the following strategy:\n",
    "    # Start with the identity transform:\n",
    "\n",
    "    overall_trafo = (1.0, 1.0, 0.0, 0.0, 0.0)\n",
    "    # Then loop for j in xrange(iterations):\n",
    "   \n",
    "    #   Transform the world_points using the curent overall_trafo\n",
    "    #     (see 05_b on how to do this)\n",
    "    #   Call get_correspoinding_points_on_wall(...)\n",
    "    #   Determine transformation which is needed \"on top of\" the current\n",
    "    #     overall_trafo: trafo = estimate_transform(...)\n",
    "    #   Concatenate the found transformation with the current overall_trafo\n",
    "    #     to obtain a new, 'combined' transformation. You may use the function\n",
    "    #     overall_trafo = concatenate_transform(trafo, overall_trafo)\n",
    "    #     to concatenate two similarities.\n",
    "    #   Note also that estimate_transform may return None.\n",
    "    # \n",
    "    # YOUR CODE HERE \n",
    "    for i in range(iterations):\n",
    "           world_points_trafo=[apply_transform(overall_trafo,p) for p in world_points]\n",
    "           lf,rf=get_corresponding_points_on_wall(world_points_trafo)\n",
    "\n",
    "           trafo=estimate_transform(lf, rf, fix_scale= True)\n",
    "\n",
    "           if trafo:\n",
    "                  overall_trafo = concatenate_transform(trafo, overall_trafo)\n",
    "           else:\n",
    "                  overall_trafo=(1.0, 1.0, 0.0, 0.0, 0.0)\n",
    "           \n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    # Return the final transformation.\n",
    "    return overall_trafo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccbc9f2b0a95b60c19b24ada631227b9",
     "grade": false,
     "grade_id": "cell-8d1d467122de8537",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Let's test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "669c3596731cc3a726c4ad0a852e6ae0",
     "grade": true,
     "grade_id": "cell-bc796b3c5b99dcab",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from math import sin, cos, sqrt, pi\n",
    "\n",
    "# Returns a new similarity transform, which is the concatenation of\n",
    "# transform a and b, \"a after b\".\n",
    "# The transform is described in the form of:\n",
    "# (scale, cos(angle), sin(angle), translate_x, translate_y)\n",
    "# i.e., the angle is described by a direction vector.\n",
    "def concatenate_transform(a, b):\n",
    "    laa, ca, sa, txa, tya = a\n",
    "    lab, cb, sb, txb, tyb = b\n",
    "    la = laa * lab\n",
    "    c = ca*cb - sa*sb\n",
    "    s = sa*cb + ca*sb\n",
    "    tx = txa + laa * ca * txb - laa * sa * tyb\n",
    "    ty = tya + laa * sa * txb + laa * ca * tyb\n",
    "    return (la, c, s, tx, ty)\n",
    "\n",
    "def public_test(the_get_icp_transform):\n",
    "    # Here are some test cases: (points, trafo_params), where trafo_params\n",
    "    # are (rotation_angle, translation_x, translation_y). Note we apply\n",
    "    # the rotation to the center of the arena, not to the lower left corner.\n",
    "    test_cases = [\n",
    "        # Test 0: two points on left bound, one point on bottom, one on top.\n",
    "        # This defines the transformation completely.\n",
    "        # First try a shift only.\n",
    "        ([(0,750),(0,1500),(1500,0),(1500,2000)], (0.0, 30.0, -50.0)),\n",
    "        # Test 1: same points, now test rotation only.\n",
    "        ([(0,750),(0,1500),(1500,0),(1500,2000)], (0.1, 0.0, 0.0)),\n",
    "        # Test 2: same points, now test translation and rotation.\n",
    "        ([(0,750),(0,1500),(1500,0),(1500,2000)], (0.1, -50.0, 80.0)),\n",
    "        # Test 3: test 0 without any top point. This will most proabably\n",
    "        # lead to an error, if fix_scale=False in estimate_transform, because\n",
    "        # the scale is ambiguous.\n",
    "        ([(0,750),(0,1500),(750,0),(1500,0)], (0.0, 80.0, -50.0)),\n",
    "    ]\n",
    "\n",
    "    # Center of the arena.\n",
    "    xc, yc = 1000., 1000.\n",
    "\n",
    "    for i, test in enumerate(test_cases):\n",
    "        points, trf = test\n",
    "        c, s, tx, ty = cos(trf[0]), sin(trf[0]), trf[1], trf[2]\n",
    "\n",
    "        # Transform world points.\n",
    "        trf_points = [ (c*(x-xc)-s*(y-yc)+xc+tx, s*(x-xc)+c*(y-yc)+yc+ty)\\\n",
    "                       for x,y in points ]\n",
    "\n",
    "        # Call function to be tested.\n",
    "        estim_trafo = the_get_icp_transform(trf_points, iterations=500)\n",
    "        if len(estim_trafo) != 5:\n",
    "            print(\"Returned trafo should be a 5-element tuple.\")\n",
    "            return False\n",
    "\n",
    "        # Compute reference trafo. This is the inverse trafo, and we also\n",
    "        # have to take into account we are rotating around the center.\n",
    "        ref_trafo = (1.0, c, -s, xc - c*(xc+tx) - s*(yc+ty),\n",
    "                     yc + s*(xc+tx) - c*(yc+ty))\n",
    "\n",
    "        # Check difference.\n",
    "        if max(abs(e-r) for e, r in zip(estim_trafo, ref_trafo)) > 0.001:\n",
    "            print(\"Test %d failed\" % i)\n",
    "            return False\n",
    "    return True\n",
    "assert(public_test(get_icp_transform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3b1ab72a299c0352b808cb89de49f675",
     "grade": false,
     "grade_id": "cell-a1cce499dd36220c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "After the test, run the following cell to produce the file `icp_wall_transform.txt` which we will look at below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample the scan. For each point, find a closest point on the\n",
    "# wall of the arena.\n",
    "# From those point pairs, estimate a transform and apply this to the pose.\n",
    "# Repeat the closest point - estimate transform loop.\n",
    "# This is an ICP algorithm.\n",
    "# 05_c_icp_wall_transform\n",
    "from lego_robot import *\n",
    "from slam_b_library import filter_step, concatenate_transform,\\\n",
    "    compute_cartesian_coordinates, write_cylinders\n",
    "from math import sqrt, atan2\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # The constants we used for the filter_step.\n",
    "    scanner_displacement = 30.0\n",
    "    ticks_to_mm = 0.349\n",
    "    robot_width = 150.0\n",
    "\n",
    "    # The start pose we obtained miraculously.\n",
    "    pose = (1850.0, 1897.0, 3.717551306747922)\n",
    "\n",
    "    # Read the logfile which contains all scans.\n",
    "    logfile = LegoLogfile()\n",
    "    logfile.read(\"robot4_motors.txt\")\n",
    "    logfile.read(\"robot4_scan.txt\")\n",
    "\n",
    "    # Iterate over all positions.\n",
    "    out_file = open(\"icp_wall_transform.txt\", \"w\")\n",
    "    for i in range(len(logfile.scan_data)):\n",
    "        # Compute the new pose.\n",
    "        pose = filter_step(pose, logfile.motor_ticks[i],\n",
    "                           ticks_to_mm, robot_width,\n",
    "                           scanner_displacement)\n",
    "\n",
    "        # Subsample points.\n",
    "        subsampled_points = get_subsampled_points(logfile.scan_data[i])\n",
    "        world_points = [LegoLogfile.scanner_to_world(pose, c)\n",
    "                        for c in subsampled_points]\n",
    "\n",
    "        # Get the transformation \n",
    "        trafo = get_icp_transform(world_points, iterations = 40)\n",
    "\n",
    "        # Correct the initial position using trafo.\n",
    "        pose = correct_pose(pose, trafo)\n",
    "\n",
    "        # Write to file.\n",
    "        # The pose.\n",
    "        print(\"F %f %f %f\" % pose, file=out_file)\n",
    "        # Write the scanner points and corresponding points.\n",
    "        write_cylinders(out_file, \"W C\",\n",
    "            [apply_transform(trafo, p) for p in world_points])\n",
    "\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "346b602618e18c3b4a454022a71f4f35",
     "grade": false,
     "grade_id": "cell-b6d0fb953ca29a50",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Congratulations, you finished Unit B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "783936ae9006ca87865646a46e5c6331",
     "grade": false,
     "grade_id": "cell-18664e4d72c1a37c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"560\"\n",
       "            height=\"315\"\n",
       "            src=\"//av.tib.eu/player/48988\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1f6cc2ed160>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you don't see a video below, run this cell.\n",
    "from IPython.display import IFrame\n",
    "IFrame(\"https://www.youtube.com/embed/zBe4IfpPRlc\" if \"YouTube\" in globals() else \"//av.tib.eu/player/48988\",\n",
    "       width=560, height=315)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "976d8f59f8f57afeadffd81dc94a6f90",
     "grade": false,
     "grade_id": "cell-63da171fe76e20b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Finally, have a look at the result yourself!\n",
    "Now, using iterations, we obtain a trajectory which does not only have a shape that looks globally correct, but also is quite smooth. Comparing it to the reference trajectory shows us we obtained a pretty good result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8741307e2893480f970144c175724177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Output(layout=Layout(width='600px')), Output(layout=Layout(width='600px')))), Ou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipy_logfile_viewer as lfv\n",
    "v = lfv.IPYLogfileViewer(files=[\"icp_wall_transform.txt\", \"robot4_reference.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "copyright": "(c) Claus Brenner 2020",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
